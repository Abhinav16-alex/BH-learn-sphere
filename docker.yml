# Docker Compose configuration for BH LearnSphere
# This file sets up all required services

version: '3.8'

services:
  # PostgreSQL Database
  db:
    image: postgres:14-alpine
    container_name: learnsphere_db
    environment:
      POSTGRES_DB: learnsphere_db
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: postgres
    volumes:
      - postgres_data:/var/lib/postgresql/data
    ports:
      - "5432:5432"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Redis for caching and Celery
  redis:
    image: redis:7-alpine
    container_name: learnsphere_redis
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Django Web Application
  web:
    build: .
    container_name: learnsphere_web
    command: >
      sh -c "python manage.py migrate &&
             python manage.py collectstatic --noinput &&
             python manage.py runserver 0.0.0.0:8000"
    volumes:
      - .:/app
      - static_volume:/app/staticfiles
      - media_volume:/app/media
    ports:
      - "8000:8000"
    env_file:
      - .env
    depends_on:
      db:
        condition: service_healthy
      redis:
        condition: service_healthy
    environment:
      - DB_HOST=db
      - REDIS_URL=redis://redis:6379/0

  # Daphne for WebSocket support
  daphne:
    build: .
    container_name: learnsphere_daphne
    command: daphne -b 0.0.0.0 -p 8001 config.asgi:application
    volumes:
      - .:/app
    ports:
      - "8001:8001"
    env_file:
      - .env
    depends_on:
      - db
      - redis
    environment:
      - DB_HOST=db
      - REDIS_URL=redis://redis:6379/0

  # Celery Worker for background tasks
  celery:
    build: .
    container_name: learnsphere_celery
    command: celery -A config worker -l info
    volumes:
      - .:/app
    env_file:
      - .env
    depends_on:
      - db
      - redis
    environment:
      - DB_HOST=db
      - REDIS_URL=redis://redis:6379/0

  # Celery Beat for scheduled tasks
  celery-beat:
    build: .
    container_name: learnsphere_celery_beat
    command: celery -A config beat -l info
    volumes:
      - .:/app
    env_file:
      - .env
    depends_on:
      - db
      - redis
    environment:
      - DB_HOST=db
      - REDIS_URL=redis://redis:6379/0

  # Nginx (Optional - for production)
  # nginx:
  #   image: nginx:alpine
  #   container_name: learnsphere_nginx
  #   volumes:
  #     - ./nginx.conf:/etc/nginx/nginx.conf
  #     - static_volume:/app/staticfiles
  #     - media_volume:/app/media
  #   ports:
  #     - "80:80"
  #   depends_on:
  #     - web

volumes:
  postgres_data:
  redis_data:
  static_volume:
  media_volume:

---
# Dockerfile
# Save this as 'Dockerfile' in your project root

FROM python:3.11-slim

# Set environment variables
ENV PYTHONDONTWRITEBYTECODE=1
ENV PYTHONUNBUFFERED=1

# Set work directory
WORKDIR /app

# Install system dependencies
RUN apt-get update && apt-get install -y \
    postgresql-client \
    build-essential \
    libpq-dev \
    && rm -rf /var/lib/apt/lists/*

# Install Python dependencies
COPY requirements.txt /app/
RUN pip install --upgrade pip
RUN pip install -r requirements.txt

# Copy project
COPY . /app/

# Create directories
RUN mkdir -p /app/staticfiles /app/media

# Collect static files
RUN python manage.py collectstatic --noinput || true

# Expose port
EXPOSE 8000

---
# .dockerignore
# Save this as '.dockerignore' in your project root

__pycache__/
*.py[cod]
*$py.class
*.so
.Python
build/
develop-eggs/
dist/
downloads/
eggs/
.eggs/
lib/
lib64/
parts/
sdist/
var/
wheels/
*.egg-info/
.installed.cfg
*.egg
venv/
ENV/
env/
*.log
local_settings.py
db.sqlite3
db.sqlite3-journal
.env
.venv
.vscode/
.idea/
*.swp
.DS_Store
Thumbs.db
.pytest_cache/
.coverage
htmlcov/
media/
staticfiles/

---
# docker-compose.prod.yml
# Production Docker Compose configuration

version: '3.8'

services:
  db:
    image: postgres:14-alpine
    container_name: learnsphere_db_prod
    environment:
      POSTGRES_DB: ${DB_NAME}
      POSTGRES_USER: ${DB_USER}
      POSTGRES_PASSWORD: ${DB_PASSWORD}
    volumes:
      - postgres_data:/var/lib/postgresql/data
    restart: unless-stopped

  redis:
    image: redis:7-alpine
    container_name: learnsphere_redis_prod
    volumes:
      - redis_data:/data
    restart: unless-stopped

  web:
    build: .
    container_name: learnsphere_web_prod
    command: gunicorn config.wsgi:application --bind 0.0.0.0:8000 --workers 4
    volumes:
      - static_volume:/app/staticfiles
      - media_volume:/app/media
    expose:
      - "8000"
    env_file:
      - .env
    depends_on:
      - db
      - redis
    restart: unless-stopped

  daphne:
    build: .
    container_name: learnsphere_daphne_prod
    command: daphne -b 0.0.0.0 -p 8001 config.asgi:application
    expose:
      - "8001"
    env_file:
      - .env
    depends_on:
      - db
      - redis
    restart: unless-stopped

  celery:
    build: .
    container_name: learnsphere_celery_prod
    command: celery -A config worker -l info
    env_file:
      - .env
    depends_on:
      - db
      - redis
    restart: unless-stopped

  nginx:
    image: nginx:alpine
    container_name: learnsphere_nginx_prod
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf
      - static_volume:/app/staticfiles
      - media_volume:/app/media
    ports:
      - "80:80"
      - "443:443"
    depends_on:
      - web
      - daphne
    restart: unless-stopped

volumes:
  postgres_data:
  redis_data:
  static_volume:
  media_volume:

---
# nginx.conf
# Save this as 'nginx.conf' in your project root

upstream django {
    server web:8000;
}

upstream daphne {
    server daphne:8001;
}

server {
    listen 80;
    server_name localhost;

    client_max_body_size 100M;

    location / {
        proxy_pass http://django;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header Host $host;
        proxy_redirect off;
    }

    location /ws/ {
        proxy_pass http://daphne;
        proxy_http_version 1.1;
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection "upgrade";
        proxy_redirect off;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Host $server_name;
    }

    location /static/ {
        alias /app/staticfiles/;
    }

    location /media/ {
        alias /app/media/;
    }
}

---
# DOCKER USAGE INSTRUCTIONS
# ========================

# 1. Build and start all services:
docker-compose up -d --build

# 2. Create database migrations:
docker-compose exec web python manage.py makemigrations
docker-compose exec web python manage.py migrate

# 3. Create superuser:
docker-compose exec web python manage.py createsuperuser

# 4. View logs:
docker-compose logs -f

# 5. Stop all services:
docker-compose down

# 6. Stop and remove volumes (WARNING: deletes all data):
docker-compose down -v

# 7. Run specific service:
docker-compose up web

# 8. Execute commands in container:
docker-compose exec web python manage.py shell

# 9. Access PostgreSQL:
docker-compose exec db psql -U postgres -d learnsphere_db

# 10. Restart a service:
docker-compose restart web

# PRODUCTION DEPLOYMENT
# =====================

# 1. Build for production:
docker-compose -f docker-compose.prod.yml up -d --build

# 2. Collect static files:
docker-compose -f docker-compose.prod.yml exec web python manage.py collectstatic --noinput

# 3. Run migrations:
docker-compose -f docker-compose.prod.yml exec web python manage.py migrate

# 4. Create superuser:
docker-compose -f docker-compose.prod.yml exec web python manage.py createsuperuser

# TROUBLESHOOTING
# ===============

# Check service status:
docker-compose ps

# View specific service logs:
docker-compose logs web
docker-compose logs db
docker-compose logs redis

# Restart all services:
docker-compose restart

# Rebuild specific service:
docker-compose up -d --build web

# Access container shell:
docker-compose exec web bash

# Check database connection:
docker-compose exec web python manage.py dbshell
